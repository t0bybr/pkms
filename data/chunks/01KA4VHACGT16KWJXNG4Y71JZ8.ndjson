{"doc_id": "01KA4VHACGT16KWJXNG4Y71JZ8", "chunk_id": "01KA4VHACGT16KWJXNG4Y71JZ8:2404db46508f", "chunk_hash": "2404db46508f", "chunk_index": 0, "text": "# Rahmen\n- Fokus: Datenschutz + Bastelspaß\n- Budget limitiert, keine Enterprise-GPUs", "tokens": 25, "section": "Rahmen", "subsection": null, "modality": "text", "language": "de"}
{"doc_id": "01KA4VHACGT16KWJXNG4Y71JZ8", "chunk_id": "01KA4VHACGT16KWJXNG4Y71JZ8:db1015054b85", "chunk_hash": "db1015054b85", "chunk_index": 1, "text": "# Notizen\n- 4B-Modelle mit Vision brauchen schnell ~40–50 GB RAM/GPU\n- 70B-Modelle in 4-Bit sind zwar theoretisch kleiner,\n  brauchen aber trotzdem sehr viel VRAM + Bandbreite\n- Realistische Zielklasse: 7B–14B mit guter Quantisierung", "tokens": 79, "section": "Notizen", "subsection": null, "modality": "text", "language": "de"}
{"doc_id": "01KA4VHACGT16KWJXNG4Y71JZ8", "chunk_id": "01KA4VHACGT16KWJXNG4Y71JZ8:d7f0774db2d5", "chunk_hash": "d7f0774db2d5", "chunk_index": 2, "text": "# TODO\n- Konkrete Benchmarks mit Ollama + Vulkan\n- Energieverbrauch vs. Nutzen abwägen", "tokens": 30, "section": "TODO", "subsection": null, "modality": "text", "language": "de"}
