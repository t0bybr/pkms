## Architektur

### ğŸ—ï¸ Base-Image & Shared Dependencies

Das System nutzt ein **Shared Base-Image** (`Dockerfile.base`) mit allen gemeinsamen Dependencies:
* **PyTorch 2.3.1 mit CUDA-Support** â€“ GPU-ready fÃ¼r zukÃ¼nftige Nutzung (z.B. RTX 3060)
* **Transformers, Sentence-Transformers, Accelerate** â€“ ML-Basis-Stack
* **FastAPI, Uvicorn, Python-Multipart** â€“ API-Framework
* **System-Libraries** â€“ ffmpeg, libgl1, poppler-utils, tesseract-ocr

**Vorteil**: PyTorch (~4GB) wird nur **1x heruntergeladen** statt 6x. Build-Cache macht spÃ¤tere Rebuilds **10-20x schneller**.

### ğŸ“¦ Microservices

* **ollama** â€“ lokales LLM (z. B. Llama 3.1 8B) fÃ¼r Antworten.
* **qwen-vl-ocr** â€“ OCR/Caption mit Qwen2.5-VL.
* **layout-detector** â€“ YOLO/DocLayNet fÃ¼r Dokument-Layout.
* **clip-embed** â€“ OpenCLIP-Image-Embeddings (fÃ¼r Skizzen/Diagramme).
* **speech-to-text** â€“ Whisper (ffmpeg) fÃ¼r Audio â†’ Text.
* **ingest-worker** â€“ Watcher + Pipelines (text/code/vision/audio) + Domains (Finanzamt).
* **lancedb** â€“ Vektor- & Metadaten-Store (dateibasiert).
* **rag-api** â€“ Retrieval (Dense + BM25) + Fusion (RRF) + Antwort.
* **redis** â€“ Cache (Queries, BM25).
* **dashboard** â€“ Statisches UI (Status, Query-Tester).
* **backup** â€“ tÃ¤gliches lokales restic-Backup.

## Datenpfade (empfohlen: 3Ã— NVMe)

* `/pkms/data`  â€“ Rohdaten, Notes, Thumbs, tmp, Inbox
* `/pkms/index` â€“ LanceDB, Logs, State (SQLite)
* `/pkms/models` â€“ Modelle/Weights
* `/pkms/backups` â€“ Restic-Repo

## Setup (Kurzform)

```bash
sudo mkdir -p /pkms/{data,index,models,backups}
sudo mkdir -p /pkms/data/{inbox,notes,thumbs,tmp}
sudo mkdir -p /pkms/index/{text,code,image,cache,logs}
sudo chown -R 1000:1000 /pkms
cp .env.example .env
```

## Start

```bash
# Docker
docker compose build && docker compose up -d
# Podman
podman compose build && podman compose up -d
```

* Dashboard: `http://127.0.0.1:3000`
* API-Health: `curl -H 'X-API-Key: change_me_local_only' http://127.0.0.1:8080/health`
* OpenAPI/Swagger: `http://127.0.0.1:8080/docs`

## Ingest â€“ so flieÃŸt es

1. **PDF/JPG/PNG** nach `/pkms/data/inbox/` â†’ `pdf2image` â†’ `layout-detector` â†’ `qwen-vl-ocr` â†’ Skizzencrops â†’ `clip-embed` â†’ Markdown + Index.
2. **Audio (wav/mp3/m4a)** nach `/pkms/data/inbox/` â†’ Whisper â†’ Markdown + Index.
3. **.md / Code** direkt in Pipelines â†’ Chunking â†’ `bge-m3` Embeddings â†’ LanceDB.
4. **Query** â†’ Dense + BM25 â†’ RRF â†’ LLM-Antwort + Treffer.

## Retrieval

* **Dense** mit `BAAI/bge-m3`.
* **Sparse** mit **BM25** (Tokenâ€‘Cache: `/tmp/bm25_tokens.json`, wird bei Bedarf neu aufgebaut).
* **Fusion** via Reciprocal Rank Fusion (RRF).
* **Bildtreffer** optional (Heuristik: Query enthÃ¤lt â€skizze/diagramm/ablauf/schema/blockâ€œ).

## Admin-Endpoints (API-Key zwingend)

* `POST /cache/flush` â€“ leert Redis.
* `POST /bm25/rebuild` â€“ baut BM25 neu (nach viel neuem Text).
* `GET  /ingest/status` â€“ verarbeitet/retries/deadletters.
* `GET  /metrics` â€“ P50/P95, Query-ZÃ¤hler.
* `GET  /health` â€“ Liveness.

## Sicherheit

* **rag-api** bindet nur `127.0.0.1:8080`, API-Key-Header `X-API-Key`.
* **Rate Limit**: einfache IPâ€‘Begrenzung Ã¼ber `RATE_LIMIT_PER_MIN` (Default 60/min).
* **OCR/Layout/CLIP/STT**: nur `127.0.0.1` und APIâ€‘Key erforderlich (`X-API-Key`).
* Modell-Container kÃ¶nnen **ohne Egress** laufen (Netz nur zum Download der Weights kurz zulassen).
* PII: Domain-Parser (z. B. Finanzamt) maskieren IBAN/Steuernummer; erweitere bei Bedarf.

## Modelle & Caching

- Qwenâ€‘VL Modell-ID per Env `QWEN_MODEL` (Default: `Qwen/Qwen2.5-VL-7B-Instruct`).
- Layoutâ€‘Detector: `doclaynet.pt` nach `MODELS/layout/doclaynet.pt`.
- Ollama: Modelle via `ollama pull â€¦` in `MODELS/llm`.
- Caches/Downloads:
  - rag-api: nutzt `INDEX/cache` als HF/Transformerâ€‘Cache (gemountet nach `/app/cache`).
  - qwen-vl-ocr, clip-embed, speech-to-text: cachen unter `MODELS/*` (HOME/HF/TORCH auf `/models`).
- Erster Start: Internetzugang erlauben, bis Modelle geladen sind.

## Volumes, Ownership & SELinux (Podman)

- Hostâ€‘Pfadvariablen: `DATA`, `INDEX`, `MODELS`, `BACKUPS` (in `.env`).
- Compose nutzt Podmanâ€‘Volumes mit Suffix `:U` (Ownershipâ€‘Anpassung fÃ¼r UID 1000).
- Bei â€Permission deniedâ€œ: Verzeichnisse anlegen und `chown -R 1000:1000` setzen.

## Idempotenz & Migration

* LanceDB-Tabellen mit **Metadaten**: `schema_version`, `embedding_model_id`, `embedding_dim`.
* **Dual-Index**-Strategie: aktuelle Tabellen `*_v1`; fÃ¼r Modellwechsel `*_v2` parallel befÃ¼llen, RAG liest beide â†’ Umschalten ohne Downtime.
* **Incremental Indexing** via SHA256 + SQLite (`ingest_state.sqlite`).

## ZuverlÃ¤ssigkeit

* **Batch-Embeddings** (Text/Code) reduzieren Overhead.
* **Retry + Dead-Letter**: `_retry` (max 3), dann `_deadletter`.
* Reprocess-Script:
  `docker compose exec ingest-worker python services/ingest_worker/scripts/reprocess_deadletter.py`
  (mit Podman: `podman compose exec ingest-worker python services/ingest_worker/scripts/reprocess_deadletter.py`)

## Backups (lokal)

* Service `backup` sichert tÃ¤glich `DATA` & `INDEX` nach `${BACKUPS}/pkms` (restic).
* Passe `BACKUPS` in `.env` an, um auf eine andere Platte zu sichern (Default: `/pkms/backups`).
* Restore-Beispiel:

```bash
docker run --rm -e RESTIC_PASSWORD=change_me -v /pkms/backups:/backups -v /restore:/restore alpine:3.20 \
  sh -lc 'apk add --no-cache restic && restic -r /backups/pkms snapshots && restic -r /backups/pkms restore latest --target /restore'
```

## HÃ¤ufige Stolpersteine

* **Erster Start dauert**, weil Modelle geladen werden.
* **Healthcheck-Binary**: `rag-api` enthÃ¤lt `curl` fÃ¼r Healthcheck.
* **GPU**: Nicht nÃ¶tig fÃ¼r Start; spÃ¤ter via `--gpus`/NVIDIA Runtime nachrÃ¼stbar.
* **Transformer/HF Caches**: `rag-api` nutzt `INDEX/cache`, MLâ€‘Services nutzen `MODELS/*` â€“ stelle Schreibrechte fÃ¼r UID 1000 sicher.
